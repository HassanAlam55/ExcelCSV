Notes of things to do
have variable beta and alph
beta and alpha derived from real data.
need to use non_extneded columns
    do hybrid skip  ahead in no crash.
    other steps in data prep that we skipped. 
    the labels code has  lower case date change that.
    time variant alpha beta - initially just use constant alpha and beta. redo with compute. 

Approach: 
    1. Multi-Class Drawdown Classifier with Multi-Horizon Validation for Drawdown
    2. Model 2: Crash Prediction (Override)
With Multi-Class Drawdown  
    2 d matrix with drawdown and hulit-Horizon
    Initially do binary
    probalbity if binary does not work.
to calcluate:
    Phase 1: Use Your Current Empirical Weights
        You mentioned you already have weights based on crash prediction:

        HY Spread: 32%
        Yield Curve: 29%
        Market Breadth: ~15-20%
        CAPE: ~10-15%
        Spread Velocity: ~10-15%
    Phase 2: If You Need to Optimize
        Use weighted F1 grid search:    

Doing Simplest model to create prediction colums

Created combined simulated portfolio and now to do simualton of how to hedge.

looks like doing short term spyputs during the draw down...

Need to simulate option prices with SPX, VIX, and risk free rate.

Need to visualize predictions


Right now not predicting downturs or detectecing them. 
Need to fix them. 

predicting time horzion, drawdown and likelihood matrix
Alternatives
    1. Random Forrest vs elastic 
    2. universal weights vs time horizon base weights
    3. Muliple walk forwards in a future time. 
First pass elastic net with universal weights. 
Modify with time horizon or Random Forrest if approach does not work. 

need to contineu it

preciions = 0.27 and recall = 1. means biased sample
Need to fix. 
now recall is lo  z scores need to be recompute
other alternatives

I am using rolling z, so that's not a problem
no predictive outcome.
Going to change all scores to positive to see if that changes anything.

making positive worked
Now check random forest or other methods
othersiwe try opimization with these results.

other features to try

Consider adding:

VIX (volatility) - Direct fear gauge
Put/Call ratio - Options market sentiment
MOVE index - Bond market volatility
Credit card delinquencies - Consumer stress (leading indicator)
Momentum indicators - RSI, MACD for S&P 500
Cross-asset correlations - Stock-bond correlation changes

Going to download all 4 separately
Combine them
Do first order for daily and quarterly
do z scores for all. 
for RSI/MACD we can do with spx data
    remember to do ahta. 

    working on combining data

need to combine new downloads with raw data all
 will need to update furter

 creadted readme to trackk in put ouput
 excel files combined
 file name in markdown MarketPredReadme.md
 will work on it today
 did not get time again
 starting again

for IEF dont need all data  - use ief close only and in analysis use the pct change and zscore for that
 Calculate IEF daily returns: ief_returns = IEF_Close.pct_change()
Calculate SPX daily returns: spx_returns = SPX_Close.pct_change()
Rolling correlation: correlation = spx_returns.rolling(60).corr(ief_returns)


next to do, i s modify process_market_data to:
    1. read columns dynamically
    2. compute as describe above  for IEF.

    need to verify output and then develop model

next chec output file and then experimeint with model
working on it.
still working on it. 

next step take modify the function that takes process_market_data output and does predictions

MarketCrashBackTest/cell 61 see how Raw_Inputs_All.csv is used because need to figure out the output and how it is used to 
    creates real_data.csv and nonoverlap_labels becuase it seems to overlap with processed_mkt_data_features.csv

    in MarketCrashBackTest/cell 62, code reararranges Raw_Inputs_all.csv to propper columsn and then then generates labels for crashes based on price_col
    Things to do: 1. see how to replace that with all_market_data.csv. 2. do we do z_scores before or after doing labels for crashes. 

labelling done on score files input processed_mkt_data_features.csv in MarketCrashBackTest.ipynb
output is to 'nonoverlap_labels.csv' in './Output/crash_labels'
need to make model now
claude code in Empirical weights optimization outline function is generate_drawdown_predictions
got data out. now to make model
new data does not improve results.
Explore alternative models

Next try in order
    1. Random forest
    2. XG Boost
    3. Ensemble Approach
    4. Two stage smethod (in the same chat that has random forest and xgboos as options)

    radforest, xgoost give similar results to the previous method.
    Now to try ensemble approach
    and then two stage
    the the modifications suggested.  in the preivious menthod
    claude suggested logistic regression.
    will look at results.s